{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202152ad-aa69-4488-9fc5-e91533df2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import torch  \n",
    "import os \n",
    "import random \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_auc_score \n",
    "import json \n",
    "from transformers import AutoTokenizer, AutoModel  \n",
    "from tqdm import tqdm \n",
    "import time \n",
    "from collections import Counter\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ab6b96-39e3-4270-8f54-1c8a141a147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Конфигурация и Гиперпараметры ---\n",
    "\n",
    "# Пути к файлам данных\n",
    "DATA_FILE = 'MY_DATA.csv' # Основной файл с логами взаимодействий\n",
    "TRACK_METADATA_FILE = 'tracks.json' # Файл с метаданными треков\n",
    "TOP_TRACKS_FILE = 'top_tracks.json' # Файл с популярными треками\n",
    "\n",
    "# Параметры текстовой модели (BERT)\n",
    "TEXT_MODEL_NAME = 'bert-base-multilingual-cased' # Название предобученной модели BERT\n",
    "MAX_TEXT_LENGTH = 32 # Максимальная длина последовательности для токенизатора BERT\n",
    "BERT_BATCH_SIZE = 128 # Размер батча для генерации эмбеддингов BERT\n",
    "\n",
    "# Размерности эмбеддингов и слоев модели\n",
    "USER_EMB_DIM = 96 # Размерность эмбеддинга пользователя\n",
    "TRACK_EMB_DIM = 96 # Размерность эмбеддинга трека\n",
    "GENRE_EMB_DIM = 48 # Размерность эмбеддинга жанра (после трансформации)\n",
    "PROJ_TEXT_EMB_DIM = 96 # Размерность проекции текстового эмбеддинга BERT для MLP\n",
    "INTERACTION_EMB_DIM = 96 # Размерность пространства для взаимодействий признаков\n",
    "\n",
    "# Параметры MLP (многослойного перцептрона)\n",
    "HIDDEN_DIMS = [384, 192] # Размеры скрытых слоев MLP\n",
    "DROPOUT_RATE = 0.45 # Коэффициент Dropout для регуляризации MLP\n",
    "\n",
    "# Параметры обучения\n",
    "TRAIN_BATCH_SIZE = 256 # Размер батча для обучения\n",
    "VAL_BATCH_SIZE = 512 # Размер батча для валидации\n",
    "REC_BATCH_SIZE = 1024 # Размер батча для генерации рекомендаций\n",
    "NUM_EPOCHS = 15 # Максимальное количество эпох обучения\n",
    "LEARNING_RATE = 5e-5 # Скорость обучения для оптимизатора AdamW\n",
    "WEIGHT_DECAY = 5e-5 # Коэффициент L2-регуляризации \n",
    "PATIENCE_LIMIT = 3 # Количество эпох без улучшения метрики валидации до ранней остановки\n",
    "NUM_NEG_SAMPLES = 4 # Количество негативных примеров на каждый позитивный для обучения\n",
    "\n",
    "# Прочие параметры\n",
    "SEED = 42 # Зерно для генераторов случайных чисел для воспроизводимости\n",
    "USE_AMP = True # Использовать ли Automatic Mixed Precision (AMP) для ускорения на GPU\n",
    "\n",
    "# Формирование имен файлов для сохранения результатов\n",
    "MODEL_SUFFIX = f\"interaction_model_v3.2_bert_{TEXT_MODEL_NAME.replace('/', '_')}_negs{NUM_NEG_SAMPLES}_amp{USE_AMP}\"\n",
    "BEST_MODEL_PATH = f\"best_{MODEL_SUFFIX}.pth\" \n",
    "RECOMMENDATIONS_FILE = f\"user_recommendations_{MODEL_SUFFIX}_top100.json\"\n",
    "TEXT_EMBEDDING_FILE_PATH = f\"track_text_embeddings_{TEXT_MODEL_NAME.replace('/', '_')}.pth\" \n",
    "LEARNED_USER_EMB_FILE = f\"learned_user_embeddings_{MODEL_SUFFIX}.pth\" \n",
    "LEARNED_TRACK_EMB_FILE = f\"learned_track_embeddings_{MODEL_SUFFIX}.pth\" \n",
    "USER_TOP_GENRES_FILE = f\"user_top_genre_ids_{MODEL_SUFFIX}.json\" \n",
    "GENRE_TOP_TRACKS_FILE = f\"genre_id_top_popular_tracks_{MODEL_SUFFIX}.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3e3258-b91a-4325-841c-35ba77229daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MPS device detected. Disabling AMP.\n",
      "Using device: mps\n",
      "AMP enabled: False\n",
      "Text model: bert-base-multilingual-cased\n",
      "Model Params -> UserEmb: 96, TrackEmb: 96, HiddenDims: [384, 192], Dropout: 0.45\n",
      "Training Params -> LR: 5e-05, WeightDecay: 5e-05, Patience: 3\n"
     ]
    }
   ],
   "source": [
    "# --- Инициализация и Настройка Окружения ---\n",
    "\n",
    "# Установка зерна для воспроизводимости\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Определение устройства (CPU, CUDA GPU, MPS GPU) и настройка AMP\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED) # Установка зерна для всех GPU\n",
    "\n",
    "elif torch.backends.mps.is_available(): # Проверка доступности MPS (для Apple Silicon)\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.manual_seed(SEED)\n",
    "    USE_AMP = False # AMP не полностью поддерживается на MPS, отключаем\n",
    "    print(\"Warning: MPS device detected. Disabling AMP.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    USE_AMP = False # AMP работает только на CUDA GPU\n",
    "    print(\"Warning: CUDA not found. Disabling AMP.\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"AMP enabled: {USE_AMP}\")\n",
    "print(f\"Text model: {TEXT_MODEL_NAME}\")\n",
    "print(f\"Model Params -> UserEmb: {USER_EMB_DIM}, TrackEmb: {TRACK_EMB_DIM}, HiddenDims: {HIDDEN_DIMS}, Dropout: {DROPOUT_RATE}\")\n",
    "print(f\"Training Params -> LR: {LEARNING_RATE}, WeightDecay: {WEIGHT_DECAY}, Patience: {PATIENCE_LIMIT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea4b923-c871-4a78-89e3-39054e649cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Parsing genre IDs from string...\n",
      "Removed 0 rows with critical NaNs.\n",
      "Target distribution:\n",
      "0    0.787289\n",
      "1    0.212711\n",
      "Name: target, dtype: float64\n",
      "Processing features for the model...\n",
      "Found 91 unique genre IDs for model input.\n"
     ]
    }
   ],
   "source": [
    "# --- Загрузка и Предобработка Данных ---\n",
    "try:\n",
    "    # Загрузка данных из CSV файла\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    # Список столбцов для удаления (если они существуют)\n",
    "    cols_to_drop = ['message', 'latency', 'recommendation', 'experiments','rnd', 'user_id', 'item_id', 'rating']\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
    "    # Удаление столбцов\n",
    "    df.drop(existing_cols_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Обработка ошибки, если файл не найден\n",
    "    print(f\"Ошибка: Файл {DATA_FILE} не найден.\")\n",
    "    exit() # Завершение скрипта\n",
    "except Exception as e:\n",
    "    # Обработка других ошибок при загрузке\n",
    "    print(f\"Ошибка при загрузке {DATA_FILE}: {e}\")\n",
    "    exit() # Завершение скрипта\n",
    "\n",
    "# Проверка наличия обязательных столбцов\n",
    "required_cols = ['time', 'duration', 'genre', 'artist', 'album', 'title', 'pop', 'user', 'track', 'timestamp']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Ошибка: Отсутствуют столбцы: {missing_cols}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "# Заполнение пропусков в текстовых столбцах значением 'Unknown'\n",
    "df.fillna({'artist': 'Unknown', 'album': 'Unknown', 'title': 'Unknown'}, inplace=True)\n",
    "# Заполнение пропусков в столбце 'genre' значением '()'\n",
    "df.fillna({'genre': '()'}, inplace=True)\n",
    "\n",
    "print(\"Parsing genre IDs from string...\")\n",
    "# Функция для извлечения списка ID жанров из строки вида '(1, 23, 45)'\n",
    "def parse_genre_ids_from_string(genre_str):\n",
    "    genre_ids = []\n",
    "    if isinstance(genre_str, str):\n",
    "        # Очистка строки от скобок и пробелов по краям\n",
    "        cleaned_str = genre_str.strip().strip('()')\n",
    "        if cleaned_str:\n",
    "            # Поиск всех чисел в строке\n",
    "            found_numbers = re.findall(r'\\d+', cleaned_str)\n",
    "            for num_str in found_numbers:\n",
    "                try:\n",
    "                    # Конвертация найденных строк в целые числа\n",
    "                    genre_ids.append(int(num_str))\n",
    "                except ValueError:\n",
    "                    # Предупреждение, если конвертация не удалась\n",
    "                    print(f\"Предупреждение: Не удалось сконвертировать ID жанра '{num_str}' из строки '{genre_str}'. Пропускается.\")\n",
    "    return genre_ids\n",
    "\n",
    "# Применение функции парсинга к столбцу 'genre' и создание нового столбца 'genre_id_list'\n",
    "df['genre_id_list'] = df['genre'].apply(parse_genre_ids_from_string)\n",
    "\n",
    "# Удаление строк с критическими пропущенными значениями (NaN)\n",
    "initial_rows = len(df)\n",
    "df.dropna(subset=['time', 'duration', 'pop', 'user', 'track', 'timestamp'], inplace=True)\n",
    "print(f\"Removed {initial_rows - len(df)} rows with critical NaNs.\")\n",
    "\n",
    "# Создание целевой переменной 'target': 1 если прослушано >= 70%, иначе 0\n",
    "df['target'] = (df['time'] >= 0.7).astype(int)\n",
    "print(f\"Target distribution:\\n{df['target'].value_counts(normalize=True)}\")\n",
    "\n",
    "print(\"Processing features for the model...\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Преобразование списка ID жанров в бинарную матрицу признаков\n",
    "genre_features_np = mlb.fit_transform(df['genre_id_list'].tolist())\n",
    "num_genres = genre_features_np.shape[1] # Количество уникальных жанров\n",
    "print(f\"Found {num_genres} unique genre IDs for model input.\")\n",
    "\n",
    "# Инициализация MinMaxScaler для масштабирования числовых признаков\n",
    "scaler = MinMaxScaler()\n",
    "numeric_features_np = scaler.fit_transform(df[['pop', 'duration']].astype(float))\n",
    "num_numeric_features = numeric_features_np.shape[1] # Количество числовых признаков\n",
    "\n",
    "cols_to_drop_model_features = ['genre']\n",
    "df.drop(cols_to_drop_model_features, axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5838c50c-ce3a-48d5-90bf-c6d0a12a6532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 unique tracks for embedding generation.\n",
      "Generating embeddings in batches of 128...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Unique Tracks: 100%|████████████████| 391/391 [03:02<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50000 embeddings, dim=768.\n",
      "Text embedding generation took 186.80s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Генерация Текстовых Эмбеддингов (BERT) ---\n",
    "start_time_bert = time.time()\n",
    "\n",
    "# Выбор уникальных треков с их метаданными (исполнитель, альбом, название)\n",
    "unique_tracks_df = df[['track', 'artist', 'album', 'title']].drop_duplicates(subset=['track']).reset_index(drop=True)\n",
    "unique_tracks_df['combined_text'] = unique_tracks_df['artist'] + \" [SEP] \" + unique_tracks_df['album'] + \" [SEP] \" + unique_tracks_df['title']\n",
    "unique_texts = unique_tracks_df['combined_text'].tolist() # Список уникальных текстовых описаний\n",
    "unique_track_ids_list = unique_tracks_df['track'].tolist() # Список соответствующих ID треков\n",
    "n_unique_texts = len(unique_texts)\n",
    "print(f\"Found {n_unique_texts} unique tracks for embedding generation.\")\n",
    "\n",
    "# Загрузка токенизатора и модели BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(TEXT_MODEL_NAME).to(device) \n",
    "bert_model.eval()\n",
    "\n",
    "unique_embeddings_list = [] \n",
    "print(f\"Generating embeddings in batches of {BERT_BATCH_SIZE}...\")\n",
    "\n",
    "# Генерация эмбеддингов батчами\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, n_unique_texts, BERT_BATCH_SIZE), desc=\"Embedding Unique Tracks\"):\n",
    "        batch_texts = unique_texts[i : i + BERT_BATCH_SIZE] # Выбор текстов для текущего батча\n",
    "        try:\n",
    "            # Токенизация текстов\n",
    "            inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=MAX_TEXT_LENGTH, return_tensors='pt').to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=(USE_AMP and device.type == 'cuda')):\n",
    "                outputs = bert_model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "            unique_embeddings_list.append(cls_embeddings)\n",
    "            del inputs, outputs, cls_embeddings\n",
    "            if device.type != 'cpu':\n",
    "                torch.cuda.empty_cache() if device.type == 'cuda' else torch.mps.empty_cache() if device.type == 'mps' else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i}: {e}\")\n",
    "\n",
    "# Объединение эмбеддингов из всех батчей в один тензор\n",
    "unique_text_embeddings_tensor = torch.cat(unique_embeddings_list, dim=0)\n",
    "bert_output_dim = unique_text_embeddings_tensor.shape[1]\n",
    "print(f\"Generated {unique_text_embeddings_tensor.shape[0]} embeddings, dim={bert_output_dim}.\")\n",
    "\n",
    "# Освобождение памяти\n",
    "del bert_model, unique_tracks_df, unique_texts, unique_embeddings_list\n",
    "\n",
    "end_time_bert = time.time()\n",
    "print(f\"Text embedding generation took {end_time_bert - start_time_bert:.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e85a61-58ed-4086-87d0-e0c5175378fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping 50000 text embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping Text Embeddings: 100%|████████| 50000/50000 [00:00<00:00, 200314.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving text embedding map to: track_text_embeddings_bert-base-multilingual-cased.pth\n",
      "Saved text embedding map.\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение Текстовых Эмбеддингов ---\n",
    "final_text_embedding_map_for_server = {} # Словарь для хранения эмбеддингов {track_id: embedding_tensor}\n",
    "num_embeddings = unique_text_embeddings_tensor.shape[0]\n",
    "num_ids = len(unique_track_ids_list)\n",
    "\n",
    "# Проверка соответствия количества эмбеддингов и ID треков\n",
    "if num_embeddings != num_ids:\n",
    "    print(f\"[ERROR] Mismatch btw embeddings & track IDs.\")\n",
    "else:\n",
    "    print(f\"Mapping {num_embeddings} text embeddings...\")\n",
    "    # Заполнение словаря\n",
    "    for i in tqdm(range(num_embeddings), desc=\"Mapping Text Embeddings\"):\n",
    "        final_text_embedding_map_for_server[unique_track_ids_list[i]] = unique_text_embeddings_tensor[i].cpu().clone()\n",
    "\n",
    "    print(f\"Saving text embedding map to: {TEXT_EMBEDDING_FILE_PATH}\")\n",
    "    try:\n",
    "        torch.save(final_text_embedding_map_for_server, TEXT_EMBEDDING_FILE_PATH)\n",
    "        print(f\"Saved text embedding map.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed saving text embedding file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ed3b85-a24b-42f9-a601-96b83924e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 unique tracks.\n",
      "Users: 10000, Tracks: 50000\n",
      "Creating user positive items lookup...\n",
      "Created user_pos_items map for 10000 users.\n",
      "Creating feature lookups by track_idx...\n",
      "Created text_emb_idx_map with 50000 entries.\n",
      "Mapping genre and numeric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping Features: 100%|███████████████| 50000/50000 [00:00<00:00, 126627.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Positive interactions for splitting: 1277685\n",
      "Split -> Train: 1022148, Val: 127768, Test: 127769\n"
     ]
    }
   ],
   "source": [
    "# --- Подготовка Данных для Модели (Индексация, Словари Признаков, Разделение) ---\n",
    "\n",
    "# Получение всех уникальных ID треков из основного DataFrame\n",
    "all_track_ids = df['track'].unique()\n",
    "print(f\"Found {len(all_track_ids)} unique tracks.\")\n",
    "\n",
    "# Создание отображений (кодировщиков) из ID пользователя/трека в непрерывные индексы (0, 1, 2, ...)\n",
    "user_encoder = {user: idx for idx, user in enumerate(df['user'].unique())}\n",
    "track_encoder = {track: idx for idx, track in enumerate(all_track_ids)}\n",
    "# Создание обратных отображений (декодеров) из индекса в ID\n",
    "user_decoder = {idx: user for user, idx in user_encoder.items()}\n",
    "track_decoder = {idx: track for track, idx in track_encoder.items()}\n",
    "\n",
    "num_users = len(user_encoder) # Общее количество уникальных пользователей\n",
    "num_tracks = len(track_encoder) # Общее количество уникальных треков\n",
    "print(f\"Users: {num_users}, Tracks: {num_tracks}\")\n",
    "\n",
    "# Добавление столбцов с индексами пользователя и трека в DataFrame\n",
    "df['user_idx'] = df['user'].map(user_encoder)\n",
    "df['track_idx'] = df['track'].map(track_encoder)\n",
    "\n",
    "if df['user_idx'].isnull().any() or df['track_idx'].isnull().any():\n",
    "    print(\"Warning: Nulls after mapping.\")\n",
    "    df.dropna(subset=['user_idx', 'track_idx'], inplace=True)\n",
    "\n",
    "print(\"Creating user positive items lookup...\")\n",
    "# Создание словаря, где ключ - user_idx, значение - set() из track_idx, с которыми пользователь взаимодействовал положительно (target=1)\n",
    "user_pos_items = {}\n",
    "required_cols_for_pos = ['target', 'user_idx', 'track_idx']\n",
    "if not all(col in df.columns for col in required_cols_for_pos):\n",
    "    print(f\"Error: Missing {required_cols_for_pos} in df.\")\n",
    "    exit()\n",
    "else:\n",
    "    try:\n",
    "        user_pos_items = df[df['target'] == 1].groupby('user_idx')['track_idx'].apply(set).to_dict()\n",
    "        print(f\"Created user_pos_items map for {len(user_pos_items)} users.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating user_pos_items: {e}\")\n",
    "        exit()\n",
    "\n",
    "print(\"Creating feature lookups by track_idx...\")\n",
    "text_emb_idx_map = {} # {track_idx: text_embedding_tensor}\n",
    "if 'final_text_embedding_map_for_server' in locals(): # Проверяем, существует ли словарь с эмбеддингами\n",
    "    for original_id, emb in final_text_embedding_map_for_server.items():\n",
    "        if original_id in track_encoder: \n",
    "            text_emb_idx_map[track_encoder[original_id]] = emb\n",
    "    print(f\"Created text_emb_idx_map with {len(text_emb_idx_map)} entries.\")\n",
    "else:\n",
    "    print(\"Warning: Text embedding map not found.\") \n",
    "\n",
    "# Запасной вариант для размерности BERT, если она не определилась ранее\n",
    "if not text_emb_idx_map and 'bert_output_dim' not in locals():\n",
    "    bert_output_dim = 768 # Стандартная размерность для bert-base\n",
    "\n",
    "genre_idx_map = {} # {track_idx: genre_features_tensor}\n",
    "numeric_idx_map = {} # {track_idx: numeric_features_tensor}\n",
    "\n",
    "# Создаем вспомогательный словарь для связи track_idx с индексом строки в исходном df,\n",
    "# чтобы корректно сопоставить признаки из numpy массивов (genre_features_np, numeric_features_np)\n",
    "track_idx_to_row_index = {}\n",
    "for idx, track_id in enumerate(df['track']): # Итерируемся по столбцу track в df\n",
    "     if track_id in track_encoder: # Если трек есть в нашем кодировщике\n",
    "          track_idx = track_encoder[track_id]\n",
    "          if track_idx not in track_idx_to_row_index:\n",
    "              track_idx_to_row_index[track_idx] = df.index[idx] \n",
    "              \n",
    "print(\"Mapping genre and numeric features...\")\n",
    "# Заполнение словарей признаков по track_idx\n",
    "for track_idx, row_idx in tqdm(track_idx_to_row_index.items(), desc=\"Mapping Features\"):\n",
    "     if row_idx < len(genre_features_np):\n",
    "         # Берем соответствующий вектор жанров, конвертируем в тензор\n",
    "         genre_idx_map[track_idx] = torch.tensor(genre_features_np[row_idx], dtype=torch.float)\n",
    "     if row_idx < len(numeric_features_np):\n",
    "         # Берем соответствующий вектор числовых признаков, конвертируем в тензор\n",
    "         numeric_idx_map[track_idx] = torch.tensor(numeric_features_np[row_idx], dtype=torch.float)\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "# Выделение только положительных взаимодействий для разделения на выборки\n",
    "df_pos = df[df['target'] == 1][['user_idx', 'track_idx']].copy()\n",
    "print(f\"Positive interactions for splitting: {len(df_pos)}\")\n",
    "\n",
    "if len(df_pos) < 10:\n",
    "    print(\"Error: Not enough positive interactions.\")\n",
    "    exit()\n",
    "\n",
    "# Получение индексов строк с положительными взаимодействиями\n",
    "pos_indices = df_pos.index.values\n",
    "\n",
    "# Разделение индексов на обучающую (80%), валидационную (10%) и тестовую (10%) выборки\n",
    "try:\n",
    "    # Пытаемся использовать стратификацию по пользователю для сохранения пропорций пользователей в выборках\n",
    "    train_pos_indices, temp_pos_indices = train_test_split(pos_indices, test_size=0.2, random_state=SEED, stratify=df_pos.loc[pos_indices, 'user_idx'])\n",
    "    val_pos_indices, test_pos_indices = train_test_split(temp_pos_indices, test_size=0.5, random_state=SEED, stratify=df_pos.loc[temp_pos_indices, 'user_idx'])\n",
    "except ValueError as e:\n",
    "    # Если стратификация не удалась (например, слишком мало примеров для некоторых пользователей)\n",
    "    print(f\"Warning: Stratification failed ({e}).\")\n",
    "    # Выполняем обычное разделение\n",
    "    train_pos_indices, temp_pos_indices = train_test_split(pos_indices, test_size=0.2, random_state=SEED)\n",
    "    val_pos_indices, test_pos_indices = train_test_split(temp_pos_indices, test_size=0.5, random_state=SEED)\n",
    "\n",
    "# Создание DataFrame для каждой выборки на основе разделенных индексов\n",
    "train_pos_data = df_pos.loc[train_pos_indices]\n",
    "val_pos_data = df_pos.loc[val_pos_indices]\n",
    "test_pos_data = df_pos.loc[test_pos_indices]\n",
    "print(f\"Split -> Train: {len(train_pos_data)}, Val: {len(val_pos_data)}, Test: {len(test_pos_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c57a6f7-3e23-4609-8d76-d95bb5a1f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating samples with negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 1022148/1022148 [00:17<00:00, 59896.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5110740 total samples.\n",
      "Generating samples with negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|████████████| 127768/127768 [00:02<00:00, 61055.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 638840 total samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Создание Датасетов и Загрузчиков Данных ---\n",
    "\n",
    "# Определение класса Датасета\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, positive_data, user_pos_items_map, all_item_indices_set,\n",
    "                 genre_map, numeric_map, text_emb_map,\n",
    "                 num_neg_samples, num_genres, num_numeric, text_emb_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            positive_data (pd.DataFrame): DataFrame с положительными взаимодействиями (user_idx, track_idx).\n",
    "            user_pos_items_map (dict): Словарь {user_idx: set(positive_track_idx)}.\n",
    "            all_item_indices_set (set): Множество всех уникальных track_idx.\n",
    "            genre_map (dict): Словарь {track_idx: genre_features_tensor}.\n",
    "            numeric_map (dict): Словарь {track_idx: numeric_features_tensor}.\n",
    "            text_emb_map (dict): Словарь {track_idx: text_embedding_tensor}.\n",
    "            num_neg_samples (int): Количество негативных примеров на один позитивный.\n",
    "            num_genres (int): Общее количество уникальных жанров (размерность вектора).\n",
    "            num_numeric (int): Количество числовых признаков.\n",
    "            text_emb_dim (int): Размерность текстового эмбеддинга.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.positive_data = positive_data\n",
    "        self.user_pos_items_map = user_pos_items_map\n",
    "        self.all_item_indices = list(all_item_indices_set)\n",
    "        self.num_items = len(self.all_item_indices)\n",
    "        self.genre_map = genre_map\n",
    "        self.numeric_map = numeric_map\n",
    "        self.text_emb_map = text_emb_map\n",
    "        self.num_neg_samples = num_neg_samples\n",
    "\n",
    "        # Создание тензоров по умолчанию для случаев, когда признак отсутствует для трека\n",
    "        self.default_genre = torch.zeros(num_genres, dtype=torch.float)\n",
    "        self.default_numeric = torch.zeros(num_numeric, dtype=torch.float)\n",
    "        # Проверка и установка размерности текстового эмбеддинга\n",
    "        if text_emb_dim is None:\n",
    "             print(\"Error: text_emb_dim is None in Dataset init! Using fallback 768.\")\n",
    "             text_emb_dim = 768 # Запасное значение\n",
    "        self.default_text_emb = torch.zeros(text_emb_dim, dtype=torch.float)\n",
    "\n",
    "        # Генерация списка всех сэмплов (положительных + отрицательных)\n",
    "        self.samples = self._generate_samples()\n",
    "        if not self.samples:\n",
    "            print(\"Warning: Generated sample list is empty!\")\n",
    "\n",
    "\n",
    "    def _generate_samples(self):\n",
    "        \"\"\"Генерирует список сэмплов (user_idx, item_idx, target).\"\"\"\n",
    "        print(\"Generating samples with negatives...\")\n",
    "        samples = []\n",
    "        if self.positive_data.empty:\n",
    "            print(\"Warning: positive_data is empty, cannot generate samples.\")\n",
    "            return samples\n",
    "\n",
    "        # Итерация по положительным примерам\n",
    "        for _, row in tqdm(self.positive_data.iterrows(), total=len(self.positive_data), desc=\"Generating samples\"):\n",
    "            u_idx, i_pos_idx = row['user_idx'], row['track_idx']\n",
    "            # Добавление положительного примера\n",
    "            samples.append((u_idx, i_pos_idx, 1.0)) # target = 1.0\n",
    "\n",
    "            # Получение множества положительных треков для данного пользователя\n",
    "            user_positive_set = self.user_pos_items_map.get(u_idx, set())\n",
    "            neg_count = 0\n",
    "            attempts = 0\n",
    "            # Генерация негативных примеров\n",
    "            while neg_count < self.num_neg_samples and attempts < self.num_neg_samples * 10: \n",
    "                # Случайный выбор трека из всех возможных\n",
    "                i_neg_idx = random.choice(self.all_item_indices)\n",
    "                # Проверка, что выбранный трек не является положительным для пользователя\n",
    "                if i_neg_idx not in user_positive_set:\n",
    "                    # Добавление негативного примера\n",
    "                    samples.append((u_idx, i_neg_idx, 0.0)) # target = 0.0\n",
    "                    neg_count += 1\n",
    "                attempts += 1 # Увеличение счетчика попыток\n",
    "\n",
    "        print(f\"Generated {len(samples)} total samples.\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Возвращает общее количество сэмплов в датасете.\"\"\"\n",
    "        if hasattr(self, 'samples'):\n",
    "            return len(self.samples)\n",
    "        else:\n",
    "            print(\"Error: self.samples attribute not found in __len__!\")\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Возвращает один сэмпл (словарь с тензорами) по индексу.\"\"\"\n",
    "        if not hasattr(self, 'samples') or not self.samples:\n",
    "             raise IndexError(\"Dataset samples are not available or empty.\")\n",
    "        if idx >= len(self.samples):\n",
    "             raise IndexError(f\"Index {idx} out of range for dataset with length {len(self.samples)}\")\n",
    "\n",
    "        # Получение user_idx, item_idx и target для данного сэмпла\n",
    "        u_idx, i_idx, target = self.samples[idx]\n",
    "\n",
    "        # Получение признаков для item_idx из соответствующих словарей\n",
    "        # Используем .get() с тензором по умолчанию, если ключ отсутствует\n",
    "        text_emb = self.text_emb_map.get(i_idx, self.default_text_emb)\n",
    "        genre_features = self.genre_map.get(i_idx, self.default_genre)\n",
    "        numeric_features = self.numeric_map.get(i_idx, self.default_numeric)\n",
    "\n",
    "        # Дополнительная проверка типов (на случай ошибок при создании словарей)\n",
    "        if not isinstance(text_emb, torch.Tensor): text_emb = self.default_text_emb\n",
    "        if not isinstance(genre_features, torch.Tensor): genre_features = self.default_genre\n",
    "        if not isinstance(numeric_features, torch.Tensor): numeric_features = self.default_numeric\n",
    "\n",
    "        # Возвращаем словарь с тензорами\n",
    "        return {\n",
    "            'user_id': torch.tensor(u_idx, dtype=torch.long), # Индекс пользователя\n",
    "            'track_id': torch.tensor(i_idx, dtype=torch.long), # Индекс трека\n",
    "            'text_emb': text_emb, # Текстовый эмбеддинг\n",
    "            'genre_features': genre_features, # Вектор жанров\n",
    "            'numeric_features': numeric_features, # Вектор числовых признаков\n",
    "            'target': torch.tensor(target, dtype=torch.float) # Целевая переменная (0.0 или 1.0)\n",
    "        }\n",
    "\n",
    "all_item_indices_set = set(track_encoder.values())\n",
    "\n",
    "if 'user_pos_items' not in locals():\n",
    "    print(\"Fatal Error: user_pos_items not defined!\")\n",
    "    exit()\n",
    "\n",
    "# Создание экземпляров датасета для обучения и валидации\n",
    "train_dataset = MyDataset(train_pos_data, user_pos_items, all_item_indices_set, genre_idx_map, numeric_idx_map, text_emb_idx_map, NUM_NEG_SAMPLES, num_genres, num_numeric_features, bert_output_dim)\n",
    "val_dataset = MyDataset(val_pos_data, user_pos_items, all_item_indices_set, genre_idx_map, numeric_idx_map, text_emb_idx_map, NUM_NEG_SAMPLES, num_genres, num_numeric_features, bert_output_dim)\n",
    "\n",
    "# Создание загрузчиков данных (DataLoader) для итерации по батчам\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=device.type == 'cuda') # Перемешивание для обучающей выборки\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=device.type == 'cuda') # Без перемешивания для валидационной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d507a3c4-35f1-46bc-8b46-faa3b1acbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Определение Модели ---\n",
    "class MyRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_tracks, text_emb_dim, genre_dim, numeric_dim,\n",
    "                 user_emb_dim=USER_EMB_DIM, track_emb_dim=TRACK_EMB_DIM,\n",
    "                 genre_emb_dim=GENRE_EMB_DIM, proj_text_emb_dim=PROJ_TEXT_EMB_DIM,\n",
    "                 interaction_emb_dim=INTERACTION_EMB_DIM, hidden_dims=HIDDEN_DIMS,\n",
    "                 dropout_rate=DROPOUT_RATE):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users (int): Общее количество уникальных пользователей.\n",
    "            num_tracks (int): Общее количество уникальных треков.\n",
    "            text_emb_dim (int): Размерность входного текстового эмбеддинга (из BERT).\n",
    "            genre_dim (int): Размерность входного вектора жанров (количество уникальных жанров).\n",
    "            numeric_dim (int): Количество числовых признаков.\n",
    "            user_emb_dim (int): Размерность эмбеддинга пользователя.\n",
    "            track_emb_dim (int): Размерность эмбеддинга трека.\n",
    "            genre_emb_dim (int): Размерность эмбеддинга жанра после трансформации.\n",
    "            proj_text_emb_dim (int): Размерность проекции текстового эмбеддинга для MLP.\n",
    "            interaction_emb_dim (int): Размерность пространства для взаимодействий.\n",
    "            hidden_dims (list): Список размеров скрытых слоев MLP.\n",
    "            dropout_rate (float): Коэффициент Dropout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Слои эмбеддингов для пользователей и треков\n",
    "        self.user_embedding = nn.Embedding(num_users, user_emb_dim)\n",
    "        self.track_embedding = nn.Embedding(num_tracks, track_emb_dim)\n",
    "\n",
    "        # Слои для проекции эмбеддингов пользователя и трека в пространство взаимодействий\n",
    "        # Если размерность совпадает, используется nn.Identity() (нет проекции)\n",
    "        self.proj_user = nn.Linear(user_emb_dim, interaction_emb_dim) if user_emb_dim != interaction_emb_dim else nn.Identity()\n",
    "        self.proj_track = nn.Linear(track_emb_dim, interaction_emb_dim) if track_emb_dim != interaction_emb_dim else nn.Identity()\n",
    "\n",
    "        # Слои для проекции текстовых эмбеддингов и жанров в пространство взаимодействий\n",
    "        self.proj_text_inter = nn.Linear(text_emb_dim, interaction_emb_dim)\n",
    "        self.proj_genre_inter = nn.Linear(genre_dim, interaction_emb_dim) \n",
    "\n",
    "        # Линейные слои (MLP) для трансформации текстовых эмбеддингов и жанров перед подачей в основной MLP\n",
    "        self.text_projection_mlp = nn.Linear(text_emb_dim, proj_text_emb_dim)\n",
    "        self.genre_transform_mlp = nn.Linear(genre_dim, genre_emb_dim)\n",
    "\n",
    "        # Расчет размерности входа для основного MLP\n",
    "        # Складываются размерности всех конкатенируемых векторов\n",
    "        mlp_input_dim = (user_emb_dim + track_emb_dim + proj_text_emb_dim +\n",
    "                         genre_emb_dim + numeric_dim + interaction_emb_dim * 3) \n",
    "        print(f\"Model - MLP Input Dim: {mlp_input_dim}\")\n",
    "\n",
    "        layers = []\n",
    "        current_dim = mlp_input_dim\n",
    "        for h_dim in hidden_dims: \n",
    "            layers.append(nn.Linear(current_dim, h_dim)) # Линейный слой\n",
    "            layers.append(nn.LayerNorm(h_dim)) # Нормализация слоя\n",
    "            layers.append(nn.GELU()) # Функция активации GELU\n",
    "            layers.append(nn.Dropout(dropout_rate)) # Dropout\n",
    "            current_dim = h_dim # Обновление текущей размерности\n",
    "\n",
    "        # Выходной слой MLP (1 нейрон для предсказания логита)\n",
    "        layers.append(nn.Linear(current_dim, 1))\n",
    "        # Объединение всех слоев в последовательную модель\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        # Инициализация весов модели\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализирует веса Embedding и Linear слоев с помощью Xavier Uniform.\"\"\"\n",
    "        for module in self.modules(): \n",
    "            if isinstance(module, nn.Embedding):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None: \n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, user_ids, track_ids, text_emb, genre_features, numeric_features):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "\n",
    "        Args:\n",
    "            user_ids (torch.Tensor): Тензор с индексами пользователей.\n",
    "            track_ids (torch.Tensor): Тензор с индексами треков.\n",
    "            text_emb (torch.Tensor): Тензор с текстовыми эмбеддингами треков.\n",
    "            genre_features (torch.Tensor): Тензор с бинарными векторами жанров.\n",
    "            numeric_features (torch.Tensor): Тензор с числовыми признаками.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Тензор с логитами предсказаний (размер батча).\n",
    "        \"\"\"\n",
    "        # 1. Получение эмбеддингов пользователей и треков\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        track_emb = self.track_embedding(track_ids)\n",
    "\n",
    "        # 2. Трансформация жанров и текстовых эмбеддингов для MLP\n",
    "        # Применяется линейный слой и ReLU\n",
    "        genre_emb_mlp = F.relu(self.genre_transform_mlp(genre_features))\n",
    "        projected_text_emb_mlp = F.relu(self.text_projection_mlp(text_emb))\n",
    "\n",
    "        # 3. Проекция эмбеддингов в пространство взаимодействий\n",
    "        # Применяется линейный слой проекции и ReLU\n",
    "        user_inter = F.relu(self.proj_user(user_emb))\n",
    "        track_inter = F.relu(self.proj_track(track_emb))\n",
    "        text_inter = F.relu(self.proj_text_inter(text_emb))\n",
    "\n",
    "        # 4. Расчет взаимодействий признаков (поэлементное умножение)\n",
    "        interaction_ut = user_inter * track_inter # Пользователь-Трек\n",
    "        interaction_ui = user_inter * text_inter # Пользователь-Текст\n",
    "        interaction_ti = track_inter * text_inter # Трек-Текст\n",
    "\n",
    "        # 5. Конкатенация всех признаков и взаимодействий для MLP\n",
    "        combined = torch.cat([\n",
    "            user_emb,                  \n",
    "            track_emb,                 \n",
    "            projected_text_emb_mlp,    \n",
    "            genre_emb_mlp,             \n",
    "            numeric_features,          \n",
    "            interaction_ut,            \n",
    "            interaction_ui,            \n",
    "            interaction_ti             \n",
    "        ], dim=1) \n",
    "\n",
    "        # 6. Прогон через MLP и получение логитов\n",
    "        return self.mlp(combined).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b16aea40-2390-4d4e-95ab-c279e3a08870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Настройка Обучения ---\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = MyRecommender(\n",
    "    num_users=num_users,\n",
    "    num_tracks=num_tracks,\n",
    "    text_emb_dim=bert_output_dim, # Размерность эмбеддинга BERT\n",
    "    genre_dim=num_genres, # Количество уникальных жанров\n",
    "    numeric_dim=num_numeric_features # Количество числовых признаков\n",
    ").to(device)\n",
    "\n",
    "# Определение оптимизатора (AdamW) и функции потерь (BCEWithLogitsLoss)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Определение планировщика скорости обучения\n",
    "# Уменьшает LR, если метрика валидации ('max' - AUC) не улучшается\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=max(1, PATIENCE_LIMIT // 2), factor=0.1, verbose=True)\n",
    "\n",
    "# Инициализация GradScaler для AMP\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(USE_AMP and device.type == 'cuda'))\n",
    "\n",
    "# Инициализация переменных для отслеживания лучшей модели и ранней остановки\n",
    "best_val_metric = -float('inf') # Лучшее значение метрики валидации (AUC)\n",
    "patience_counter = 0 # Счетчик эпох без улучшения\n",
    "\n",
    "# Запуск таймера обучения\n",
    "training_start_time = time.time()\n",
    "print(f\"Starting training for up to {NUM_EPOCHS} epochs...\")\n",
    "\n",
    "\n",
    "# --- Цикл Обучения ---\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start_time = time.time() # Время начала эпохи\n",
    "    # --- Фаза Обучения ---\n",
    "    model.train() # Перевод модели в режим обучения\n",
    "    train_loss = 0.0 # Суммарные потери на обучающей выборке за эпоху\n",
    "    # Обертка загрузчика данных в tqdm для прогресс-бара\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\", leave=False)\n",
    "\n",
    "    for batch in train_loop:\n",
    "        # Перемещение данных батча на выбранное устройство\n",
    "        user_ids = batch['user_id'].to(device)\n",
    "        track_ids = batch['track_id'].to(device)\n",
    "        text_emb = batch['text_emb'].to(device)\n",
    "        genre_features = batch['genre_features'].to(device)\n",
    "        numeric_features = batch['numeric_features'].to(device)\n",
    "        targets_batch = batch['target'].to(device) \n",
    "\n",
    "        # Обнуление градиентов перед обратным проходом\n",
    "        optimizer.zero_grad(set_to_none=True) \n",
    "\n",
    "        # Прямой проход с использованием AMP \n",
    "        with torch.cuda.amp.autocast(enabled=(USE_AMP and device.type=='cuda')):\n",
    "            # Получение логитов от модели\n",
    "            outputs = model(user_ids, track_ids, text_emb, genre_features, numeric_features)\n",
    "            # Расчет потерь\n",
    "            loss = loss_fn(outputs, targets_batch)\n",
    "\n",
    "        # Обратный проход с использованием GradScaler \n",
    "        scaler.scale(loss).backward() # Масштабирование потерь перед обратным проходом\n",
    "        scaler.step(optimizer) # Шаг оптимизатора (с проверкой градиентов)\n",
    "        scaler.update() # Обновление масштаба GradScaler\n",
    "\n",
    "        # Накопление потерь и обновление прогресс-бара\n",
    "        train_loss += loss.item() # Добавляем значение потерь \n",
    "        train_loop.set_postfix(loss=loss.item()) # Отображение текущих потерь в tqdm\n",
    "\n",
    "    # Расчет средней потери на обучающей выборке за эпоху\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- Фаза Валидации ---\n",
    "    model.eval() \n",
    "    val_loss = 0.0 # Суммарные потери на валидационной выборке\n",
    "    all_targets = [] # Список для хранения всех целевых значений\n",
    "    all_preds = [] # Список для хранения всех предсказаний (вероятностей)\n",
    "    val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\", leave=False)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in val_loop:\n",
    "            # Перемещение данных батча на устройство\n",
    "            user_ids = batch['user_id'].to(device)\n",
    "            track_ids = batch['track_id'].to(device)\n",
    "            text_emb = batch['text_emb'].to(device)\n",
    "            genre_features = batch['genre_features'].to(device)\n",
    "            numeric_features = batch['numeric_features'].to(device)\n",
    "            targets_batch = batch['target'].to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(USE_AMP and device.type=='cuda')):\n",
    "                outputs = model(user_ids, track_ids, text_emb, genre_features, numeric_features)\n",
    "                loss = loss_fn(outputs, targets_batch) \n",
    "\n",
    "            val_loss += loss.item() \n",
    "\n",
    "            # Получение вероятностей с помощью сигмоиды\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.extend(preds) \n",
    "            all_targets.extend(targets_batch.cpu().numpy()) \n",
    "\n",
    "    # Расчет средней потери на валидационной выборке\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    # Расчет AUC ROC\n",
    "    try:\n",
    "        # Могут возникнуть ошибки, если в выборке только один класс\n",
    "        val_auc = roc_auc_score(all_targets, all_preds)\n",
    "    except ValueError:\n",
    "        val_auc = 0.0 # В случае ошибки присваиваем AUC=0\n",
    "        print(\"Warning: AUC calculation failed.\")\n",
    "\n",
    "    epoch_end_time = time.time() # Время окончания эпохи\n",
    "    # Вывод результатов эпохи\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} [{epoch_end_time - epoch_start_time:.2f}s] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Шаг планировщика LR на основе метрики валидации (AUC)\n",
    "    scheduler.step(val_auc)\n",
    "\n",
    "    # --- Проверка Улучшения и Ранняя Остановка ---\n",
    "    current_metric = val_auc # Текущая метрика для сравнения\n",
    "\n",
    "    if current_metric > best_val_metric:\n",
    "        # Если метрика улучшилась\n",
    "        best_val_metric = current_metric\n",
    "        # Сохранение состояния модели (весов)\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"*** New best model saved (Val AUC: {best_val_metric:.4f}) ***\")\n",
    "        patience_counter = 0 \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Val AUC didn't improve. Patience: {patience_counter}/{PATIENCE_LIMIT}\")\n",
    "\n",
    "    # Проверка условия для ранней остановки\n",
    "    if patience_counter >= PATIENCE_LIMIT:\n",
    "        print(f\"Early stopping @ epoch {epoch+1}.\")\n",
    "        break \n",
    "\n",
    "training_end_time = time.time() \n",
    "print(f\"Training finished in {training_end_time - training_start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b1c7fb-e218-4340-addc-883816b26dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Извлечение и Сохранение Обученных Эмбеддингов ---\n",
    "learned_user_embeddings = None\n",
    "learned_track_embeddings = None\n",
    "\n",
    "# Проверка существования файла с лучшей моделью\n",
    "if not os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f\"Error: Best model not found at {BEST_MODEL_PATH}. Cannot extract embeddings.\")\n",
    "else:\n",
    "    print(f\"Loading best model: {BEST_MODEL_PATH}...\")\n",
    "    # Создание экземпляра архитектуры модели\n",
    "    model_loaded = MyRecommender(num_users=num_users, num_tracks=num_tracks, text_emb_dim=bert_output_dim, genre_dim=num_genres, numeric_dim=num_numeric_features).to(device)\n",
    "    # Загрузка сохраненных весов\n",
    "    model_loaded.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device)) # map_location для корректной загрузки на любое устройство\n",
    "    model_loaded.eval()\n",
    "    print(f\" Loaded.\")\n",
    "\n",
    "    print(\"Extracting embeddings...\")\n",
    "    try:\n",
    "        # Извлечение тензоров эмбеддингов из модели\n",
    "        user_embeddings_tensor = model_loaded.user_embedding.weight.detach().cpu()\n",
    "        track_embeddings_tensor = model_loaded.track_embedding.weight.detach().cpu()\n",
    "        print(f\"UserEmb Shape: {user_embeddings_tensor.shape}, TrackEmb Shape: {track_embeddings_tensor.shape}\")\n",
    "\n",
    "        # Создание словарей для сохранения эмбеддингов с оригинальными ID\n",
    "        learned_user_embedding_map = {}\n",
    "        print(\"Mapping users...\")\n",
    "        for original_user_id, user_idx in tqdm(user_encoder.items(), desc=\"Map User Emb\"):\n",
    "            # Проверка, что индекс пользователя не выходит за пределы тензора эмбеддингов\n",
    "            if user_idx < user_embeddings_tensor.shape[0]:\n",
    "                learned_user_embedding_map[original_user_id] = user_embeddings_tensor[user_idx]\n",
    "            else:\n",
    "                 learned_user_embedding_map[original_user_id] = None \n",
    "                \n",
    "        learned_user_embedding_map = {k:v for k,v in learned_user_embedding_map.items() if v is not None}\n",
    "\n",
    "        learned_track_embedding_map = {}\n",
    "        print(\"Mapping tracks...\")\n",
    "        for original_track_id, track_idx in tqdm(track_encoder.items(), desc=\"Map Track Emb\"):\n",
    "             if track_idx < track_embeddings_tensor.shape[0]:\n",
    "                 learned_track_embedding_map[original_track_id] = track_embeddings_tensor[track_idx]\n",
    "\n",
    "        # Сохранение словарей эмбеддингов\n",
    "        print(f\"Saving user embeddings to {LEARNED_USER_EMB_FILE}...\")\n",
    "        torch.save(learned_user_embedding_map, LEARNED_USER_EMB_FILE)\n",
    "        print(f\" Saved {len(learned_user_embedding_map)} user embeddings.\")\n",
    "        learned_user_embeddings = learned_user_embedding_map \n",
    "\n",
    "        print(f\"Saving track embeddings to {LEARNED_TRACK_EMB_FILE}...\")\n",
    "        torch.save(learned_track_embedding_map, LEARNED_TRACK_EMB_FILE)\n",
    "        print(f\" Saved {len(learned_track_embedding_map)} track embeddings.\")\n",
    "        learned_track_embeddings = learned_track_embedding_map\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting or saving embeddings: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c93382f-a326-46dd-816e-2081cf0e43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Генерация Рекомендаций ---\n",
    "recommendations_list = [] # Список для хранения рекомендаций [{'user': user_id, 'tracks': [track_id1, ...]}, ...]\n",
    "\n",
    "# Проверка, была ли модель успешно загружена\n",
    "if 'model_loaded' not in locals() or not hasattr(model_loaded, 'state_dict') or model_loaded is None:\n",
    "    print(\"Error: Best model not available or not loaded correctly. Cannot generate recommendations.\")\n",
    "else:\n",
    "    model_loaded.eval() \n",
    "\n",
    "    # Отладочная проверка наличия всех необходимых переменных\n",
    "    print(\"Debug: Checking required variables for recommendation generation...\")\n",
    "    required_vars = ['genre_idx_map', 'numeric_idx_map', 'text_emb_idx_map', 'user_pos_items', 'track_encoder', 'user_encoder', 'track_decoder']\n",
    "    all_vars_available = True\n",
    "    for var_name in required_vars:\n",
    "        if var_name not in locals():\n",
    "            print(f\"Debug: Variable '{var_name}' is not in local scope.\")\n",
    "            all_vars_available = False\n",
    "        elif locals()[var_name] is None:\n",
    "             print(f\"Debug: Variable '{var_name}' is None.\")\n",
    "             all_vars_available = False\n",
    "        # Проверка на пустоту для словарей и списков\n",
    "        elif hasattr(locals()[var_name], '__len__') and len(locals()[var_name]) == 0:\n",
    "             print(f\"Debug: Variable '{var_name}' is available but empty.\")\n",
    "        elif hasattr(locals()[var_name], '__len__'):\n",
    "             print(f\"Debug: Variable '{var_name}' is available, size: {len(locals()[var_name])}\")\n",
    "        else:\n",
    "             print(f\"Debug: Variable '{var_name}' is available, type: {type(locals()[var_name])}\")\n",
    "\n",
    "    if not all_vars_available:\n",
    "         print(\"Error: Feature maps or encoders/decoders unavailable. Cannot generate recommendations.\")\n",
    "    else:\n",
    "        print(\"All required feature maps and encoders/decoders are available.\")\n",
    "        print(\"Preparing features for all tracks...\")\n",
    "\n",
    "        # Получение списка всех индексов треков\n",
    "        all_items_internal_indices = list(track_encoder.values())\n",
    "        num_all_items_for_rec = len(all_items_internal_indices)\n",
    "\n",
    "        # Проверка наличия ключевых переменных конфигурации\n",
    "        required_config_vars = ['bert_output_dim', 'num_genres', 'num_numeric_features', 'device', 'USE_AMP', 'REC_BATCH_SIZE']\n",
    "        if not all(var in locals() for var in required_config_vars):\n",
    "             print(\"Fatal Error: Core configuration variables (dimensions, device, batch size, AMP) are not defined.\")\n",
    "        else:\n",
    "            # Создание тензоров по умолчанию на нужном устройстве\n",
    "            default_text_emb = torch.zeros(bert_output_dim, dtype=torch.float, device=device)\n",
    "            default_genre = torch.zeros(num_genres, dtype=torch.float, device=device)\n",
    "            default_numeric = torch.zeros(num_numeric_features, dtype=torch.float, device=device)\n",
    "\n",
    "            # Подготовка тензоров с признаками для всех треков\n",
    "            # Используем .get() со значением по умолчанию, если признак отсутствует\n",
    "            all_items_text_emb = torch.stack([text_emb_idx_map.get(i, default_text_emb.cpu()).to(device) for i in all_items_internal_indices])\n",
    "            all_items_genre_feat = torch.stack([genre_idx_map.get(i, default_genre.cpu()).to(device) for i in all_items_internal_indices])\n",
    "            all_items_numeric_feat = torch.stack([numeric_idx_map.get(i, default_numeric.cpu()).to(device) for i in all_items_internal_indices])\n",
    "            # Тензор с индексами всех треков\n",
    "            all_items_internal_indices_tensor = torch.tensor(all_items_internal_indices, dtype=torch.long).to(device)\n",
    "\n",
    "            # Получение списка оригинальных ID пользователей\n",
    "            unique_original_user_ids = list(user_encoder.keys())\n",
    "            num_users_for_rec = len(unique_original_user_ids)\n",
    "\n",
    "            print(f\"Generating Top-100 recommendations for {num_users_for_rec} users...\")\n",
    "            rec_gen_start_time = time.time()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                user_loop = tqdm(unique_original_user_ids, desc=\"Generating Recs per User\")\n",
    "\n",
    "                # Итерация по каждому пользователю\n",
    "                for original_user_id in user_loop:\n",
    "                    if original_user_id in user_encoder: # Проверка, что пользователь есть в кодировщике\n",
    "                        internal_user_idx = user_encoder[original_user_id] # Получаем индекс пользователя\n",
    "                        # Создаем тензор с индексом пользователя (повторяется для батча)\n",
    "                        user_idx_tensor = torch.tensor([internal_user_idx], device=device, dtype=torch.long)\n",
    "                        # Получаем множество треков, с которыми пользователь уже взаимодействовал\n",
    "                        user_positive_set = user_pos_items.get(internal_user_idx, set())\n",
    "\n",
    "                        user_scores = [] # Список для хранения скоров (логитов) для этого пользователя\n",
    "                        item_indices_scored = [] # Список для хранения индексов треков, для которых получены скоры\n",
    "\n",
    "                        # Итерация по всем трекам батчами\n",
    "                        for i in range(0, num_all_items_for_rec, REC_BATCH_SIZE):\n",
    "                            # Выбор батча индексов и признаков треков\n",
    "                            batch_track_indices = all_items_internal_indices_tensor[i : i + REC_BATCH_SIZE]\n",
    "                            batch_text_emb = all_items_text_emb[i : i + REC_BATCH_SIZE]\n",
    "                            batch_genre_feat = all_items_genre_feat[i : i + REC_BATCH_SIZE]\n",
    "                            batch_numeric_feat = all_items_numeric_feat[i : i + REC_BATCH_SIZE]\n",
    "\n",
    "                            current_batch_size = len(batch_track_indices)\n",
    "                            # Расширяем тензор индекса пользователя до размера батча\n",
    "                            user_idx_tensor_batch = user_idx_tensor.expand(current_batch_size)\n",
    "\n",
    "                            # Получение скоров от модели \n",
    "                            with torch.cuda.amp.autocast(enabled=(USE_AMP and device.type == 'cuda')):\n",
    "                                scores = model_loaded(\n",
    "                                    user_ids=user_idx_tensor_batch,\n",
    "                                    track_ids=batch_track_indices,\n",
    "                                    text_emb=batch_text_emb,\n",
    "                                    genre_features=batch_genre_feat,\n",
    "                                    numeric_features=batch_numeric_feat\n",
    "                                )\n",
    "\n",
    "                            # Добавляем скоры и индексы треков в списки\n",
    "                            user_scores.append(scores.cpu())\n",
    "                            item_indices_scored.extend(batch_track_indices.cpu().tolist())\n",
    "\n",
    "                        # Объединение скоров из всех батчей для пользователя\n",
    "                        all_user_scores = torch.cat(user_scores)\n",
    "                        # Преобразование списка индексов в numpy массив\n",
    "                        all_items_indices_scored = np.array(item_indices_scored)\n",
    "\n",
    "                        # Фильтрация: удаляем треки, с которыми пользователь уже взаимодействовал\n",
    "                        # Создаем маску: True для треков, которых нет в user_positive_set\n",
    "                        mask = np.isin(all_items_indices_scored, list(user_positive_set), invert=True)\n",
    "                        # Применяем маску к скорам и индексам\n",
    "                        filtered_scores = all_user_scores[mask]\n",
    "                        filtered_indices = all_items_indices_scored[mask]\n",
    "\n",
    "                        # Выбор топ-100 рекомендаций\n",
    "                        if len(filtered_scores) == 0:\n",
    "                            # Если после фильтрации не осталось треков\n",
    "                            top_original_track_ids = []\n",
    "                        else:\n",
    "                            # Определяем количество рекомендаций (не больше доступного и не больше 100)\n",
    "                            k = min(100, len(filtered_scores))\n",
    "                            # Находим индексы k наибольших скоров\n",
    "                            _, top_relative_indices = torch.topk(filtered_scores, k=k, largest=True)\n",
    "                            # Получаем соответствующие внутренние индексы треков\n",
    "                            top_internal_track_indices = filtered_indices[top_relative_indices.numpy()]\n",
    "                            # Декодируем внутренние индексы в оригинальные ID треков\n",
    "                            top_original_track_ids = [track_decoder.get(idx, -1) for idx in top_internal_track_indices]\n",
    "                            # Удаляем возможные ошибки декодирования (-1)\n",
    "                            top_original_track_ids = [tid for tid in top_original_track_ids if tid != -1]\n",
    "\n",
    "                        # Добавление рекомендаций для пользователя в общий список\n",
    "                        recommendations_list.append({'user': original_user_id, 'tracks': top_original_track_ids})\n",
    "\n",
    "            rec_gen_end_time = time.time()\n",
    "            print(f\"Recommendation generation complete in {rec_gen_end_time - rec_gen_start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a6d24ba-6538-4b70-8e74-0ddeadbdd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Сохранение Рекомендаций ---\n",
    "\n",
    "# Класс для корректной сериализации numpy и torch типов в JSON\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        # Конвертация numpy int типов в Python int\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        # Конвертация numpy float типов в Python float\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        # Конвертация numpy массивов в Python list\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        # Конвертация torch тензоров в Python list\n",
    "        elif isinstance(obj, (torch.Tensor,)):\n",
    "            return obj.tolist()\n",
    "        # Конвертация set в list\n",
    "        elif isinstance(obj, (set,)):\n",
    "            return list(obj)\n",
    "        # Стандартное поведение для других типов\n",
    "        return super().default(obj)\n",
    "\n",
    "# Функция для сохранения данных в формате JSON Lines (.jsonl)\n",
    "def save_jsonlines(data, filename):\n",
    "    print(f\"\\nSaving recommendations to {filename}...\")\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            # Итерация по списку рекомендаций\n",
    "            for item in tqdm(data, desc=\"Saving recommendations\"):\n",
    "                try:\n",
    "                    # Подготовка элемента для записи (гарантируем нужные типы)\n",
    "                    processed_item = {\n",
    "                        'user': item.get('user'),\n",
    "                        'tracks': [track for track in item.get('tracks', [])]\n",
    "                    }\n",
    "                    # Явная конвертация user ID, если это numpy integer\n",
    "                    if isinstance(processed_item['user'], np.integer):\n",
    "                         processed_item['user'] = int(processed_item['user'])\n",
    "                    # Явная конвертация track ID, если это numpy integer\n",
    "                    processed_item['tracks'] = [int(t) if isinstance(t, np.integer) else t for t in processed_item['tracks']]\n",
    "\n",
    "                    # Сериализация элемента в JSON строку с использованием кастомного энкодера\n",
    "                    # ensure_ascii=False для корректного сохранения не-ASCII символов (если есть в ID)\n",
    "                    json_line = json.dumps(processed_item, ensure_ascii=False, cls=NumpyEncoder)\n",
    "                    # Запись JSON строки в файл с добавлением символа новой строки\n",
    "                    f.write(json_line + '\\n')\n",
    "                except Exception as e_inner:\n",
    "                    # Обработка ошибок при сериализации отдельного элемента\n",
    "                    print(f\"Error serializing item for user {item.get('user')}: {e_inner}\\nItem: {item}\")\n",
    "\n",
    "        print(f\"Recommendations saved to {filename}\")\n",
    "    except Exception as e_outer:\n",
    "        # Обработка ошибок при записи в файл\n",
    "        print(f\"Error writing file {filename}: {e_outer}\")\n",
    "\n",
    "# Проверка наличия переменной с путем к файлу рекомендаций\n",
    "if 'RECOMMENDATIONS_FILE' in locals():\n",
    "     save_jsonlines(recommendations_list, RECOMMENDATIONS_FILE) # Вызов функции сохранения\n",
    "else:\n",
    "     print(\"Error: RECOMMENDATIONS_FILE is not defined. Cannot save recommendations.\")\n",
    "\n",
    "print(f'\\n--- Script Finished ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc9b0e-ba7d-4c70-bf30-d9458d8eed74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
